{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supermarket Sales Analysis\n",
    "This notebook conducts a comprehensive analysis of supermarket sales data stored in a MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as connector\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection and Setup\n",
    "This section connects to the MySQL database, creates the `supermarket_sales` database and the `Sales` table if they do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Configuration for the database connection\n",
    "dbconfig = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "connection = connector.connect(**dbconfig)\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created and in use: supermarket_sales\n"
     ]
    }
   ],
   "source": [
    "# Create the supermarket_sales databes if it does not exist\n",
    "db_create_query = \"CREATE DATABASE IF NOT EXISTS supermarket_sales;\"\n",
    "db_use_query = \"USE supermarket_sales;\"\n",
    "cursor.execute(db_create_query)\n",
    "cursor.execute(db_use_query)\n",
    "\n",
    "# Check if the database is created and in use\n",
    "check_query = \"SELECT DATABASE() AS current_database;\"\n",
    "cursor.execute(check_query)\n",
    "result = cursor.fetchone()\n",
    "\n",
    "if result[0] == \"supermarket_sales\":\n",
    "    print(\"Database created and in use: supermarket_sales\")\n",
    "else:\n",
    "    print(\"Database not created or not in use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales table created or already exists.\n",
      "Sales table exists.\n"
     ]
    }
   ],
   "source": [
    "table_create_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sales (\n",
    "    invoice_id VARCHAR(20),\n",
    "    branch CHAR(1),\n",
    "    city VARCHAR(50),\n",
    "    customer_type VARCHAR(10),\n",
    "    gender VARCHAR(10),\n",
    "    product_line VARCHAR(50),\n",
    "    unit_price DECIMAL(10, 2),\n",
    "    quantity INT,\n",
    "    tax DECIMAL(10, 2),\n",
    "    total DECIMAL(10, 2),\n",
    "    date DATE,\n",
    "    time TIME,\n",
    "    payment VARCHAR(20),\n",
    "    cogs DECIMAL(10, 2),\n",
    "    gross_margin_percentage DECIMAL(5, 2),\n",
    "    gross_income DECIMAL(10, 2),\n",
    "    rating DECIMAL(4, 2)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(table_create_query)\n",
    "print(\"Sales table created or already exists.\")\n",
    "\n",
    "\n",
    "# Check if the table is created\n",
    "check_query = \"SHOW TABLES LIKE 'sales';\"\n",
    "cursor.execute(check_query)\n",
    "result = cursor.fetchall()\n",
    "if result:\n",
    "    print(\"Sales table exists.\")\n",
    "else:\n",
    "    print(\"Sales table does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Insertion\n",
    "This section reads sales data from a CSV file and inserts it into the `Sales` table in the MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('750-67-8428', 'A', 'Yangon', 'Member', 'Female', 'Health and beauty', Decimal('74.69'), 7, Decimal('26.14'), Decimal('548.97'), datetime.date(2019, 1, 5), datetime.timedelta(seconds=47280), 'Ewallet', Decimal('522.83'), Decimal('4.76'), Decimal('26.14'), Decimal('9.10'))\n",
      "('226-31-3081', 'C', 'Naypyitaw', 'Normal', 'Female', 'Electronic accessories', Decimal('15.28'), 5, Decimal('3.82'), Decimal('80.22'), datetime.date(2019, 3, 8), datetime.timedelta(seconds=37740), 'Cash', Decimal('76.40'), Decimal('4.76'), Decimal('3.82'), Decimal('9.60'))\n",
      "('631-41-3108', 'A', 'Yangon', 'Normal', 'Male', 'Home and lifestyle', Decimal('46.33'), 7, Decimal('16.22'), Decimal('340.53'), datetime.date(2019, 3, 3), datetime.timedelta(seconds=48180), 'Credit card', Decimal('324.31'), Decimal('4.76'), Decimal('16.22'), Decimal('7.40'))\n",
      "('123-19-1176', 'A', 'Yangon', 'Member', 'Male', 'Health and beauty', Decimal('58.22'), 8, Decimal('23.29'), Decimal('489.05'), datetime.date(2019, 1, 27), datetime.timedelta(seconds=73980), 'Ewallet', Decimal('465.76'), Decimal('4.76'), Decimal('23.29'), Decimal('8.40'))\n",
      "('373-73-7910', 'A', 'Yangon', 'Normal', 'Male', 'Sports and travel', Decimal('86.31'), 7, Decimal('30.21'), Decimal('634.38'), datetime.date(2019, 2, 8), datetime.timedelta(seconds=38220), 'Ewallet', Decimal('604.17'), Decimal('4.76'), Decimal('30.21'), Decimal('5.30'))\n",
      "('699-14-3026', 'C', 'Naypyitaw', 'Normal', 'Male', 'Electronic accessories', Decimal('85.39'), 7, Decimal('29.89'), Decimal('627.62'), datetime.date(2019, 3, 25), datetime.timedelta(seconds=66600), 'Ewallet', Decimal('597.73'), Decimal('4.76'), Decimal('29.89'), Decimal('4.10'))\n",
      "('355-53-5943', 'A', 'Yangon', 'Member', 'Female', 'Electronic accessories', Decimal('68.84'), 6, Decimal('20.65'), Decimal('433.69'), datetime.date(2019, 2, 25), datetime.timedelta(seconds=52560), 'Ewallet', Decimal('413.04'), Decimal('4.76'), Decimal('20.65'), Decimal('5.80'))\n",
      "('315-22-5665', 'C', 'Naypyitaw', 'Normal', 'Female', 'Home and lifestyle', Decimal('73.56'), 10, Decimal('36.78'), Decimal('772.38'), datetime.date(2019, 2, 24), datetime.timedelta(seconds=41880), 'Ewallet', Decimal('735.60'), Decimal('4.76'), Decimal('36.78'), Decimal('8.00'))\n",
      "('665-32-9167', 'A', 'Yangon', 'Member', 'Female', 'Health and beauty', Decimal('36.26'), 2, Decimal('3.63'), Decimal('76.15'), datetime.date(2019, 1, 10), datetime.timedelta(seconds=62100), 'Credit card', Decimal('72.52'), Decimal('4.76'), Decimal('3.63'), Decimal('7.20'))\n",
      "('692-92-5582', 'B', 'Mandalay', 'Member', 'Female', 'Food and beverages', Decimal('54.84'), 3, Decimal('8.23'), Decimal('172.75'), datetime.date(2019, 2, 20), datetime.timedelta(seconds=48420), 'Credit card', Decimal('164.52'), Decimal('4.76'), Decimal('8.23'), Decimal('5.90'))\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file using Pandas\n",
    "df = pd.read_csv('../data/supermarket_sales.csv')\n",
    "\n",
    "# Convert the 'date' column to datetime and format it\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Clip the 'rating' values to ensure they are within the 0 to 10.00 range\n",
    "df['Rating'] = df['Rating'].clip(0, 10.00)\n",
    "\n",
    "# Insert data into the sales table\n",
    "insert_query = \"\"\"\n",
    "    INSERT INTO sales (invoice_id, branch, city, customer_type, gender, product_line, unit_price, quantity, tax, total, date, time, payment, cogs, gross_margin_percentage, gross_income, rating)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "cursor.executemany(insert_query, data)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "# Check if the data is inserted\n",
    "check_query = \"SELECT * FROM sales LIMIT 10;\"\n",
    "cursor.execute(check_query)\n",
    "result = cursor.fetchall()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "This section contains various SQL queries to analyze the sales data. The results are displayed as Pandas DataFrames for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_dataframe(cursor, result):\n",
    "    \"\"\"\n",
    "    Convert SQL query result to a pandas DataFrame and display it.\n",
    "    \n",
    "    Parameters:\n",
    "    cursor: Database cursor with description attribute\n",
    "    result: Result set from the executed query\n",
    "\n",
    "    Returns:\n",
    "    df_result: pandas DataFrame containing the query results\n",
    "    \"\"\"\n",
    "    # Get the column names from the cursor description\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    \n",
    "    # Create a DataFrame from the fetched results\n",
    "    df_result = pd.DataFrame(result, columns=columns)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df_result)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Performance by Branch\n",
    "This query calculates the total sales for each branch and displays them in descending order of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  branch total_sales\n",
      "0      C   110568.86\n",
      "1      A   106200.57\n",
      "2      B   106198.00\n"
     ]
    }
   ],
   "source": [
    "# Sales Performance by Branch\n",
    "branch_performance_query = \"\"\"\n",
    "SELECT branch, SUM(total) AS total_sales\n",
    "FROM sales\n",
    "GROUP BY branch\n",
    "ORDER BY total_sales DESC;\n",
    "\"\"\"\n",
    "cursor.execute(branch_performance_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Rating by Product Line\n",
    "This query calculates the average customer rating for each product line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             product_line avg_rating\n",
      "0      Food and beverages   7.113218\n",
      "1     Fashion accessories   7.029213\n",
      "2       Health and beauty   7.003289\n",
      "3  Electronic accessories   6.924706\n",
      "4       Sports and travel   6.916265\n",
      "5      Home and lifestyle   6.837500\n"
     ]
    }
   ],
   "source": [
    "# Average Rating by Product Line\n",
    "product_line_rating_query = \"\"\"\n",
    "SELECT product_line, AVG(rating) AS avg_rating\n",
    "FROM sales\n",
    "GROUP BY product_line\n",
    "ORDER BY avg_rating DESC;\n",
    "\"\"\"\n",
    "cursor.execute(product_line_rating_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Sales\n",
    "This query provides a summary of daily sales, including the total sales amount, total sales units, and the average item price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sales_date total_sales_amount total_sales_units avg_item_price\n",
      "0   2019-01-01            4745.19                81      58.582593\n",
      "1   2019-01-02            1945.50                48      40.531250\n",
      "2   2019-01-03            2078.12                37      56.165405\n",
      "3   2019-01-04            1623.68                32      50.740000\n",
      "4   2019-01-05            3536.69                55      64.303455\n",
      "..         ...                ...               ...            ...\n",
      "84  2019-03-26            1962.52                52      37.740769\n",
      "85  2019-03-27            2902.81                45      64.506889\n",
      "86  2019-03-28            2229.42                48      46.446250\n",
      "87  2019-03-29            4023.25                54      74.504630\n",
      "88  2019-03-30            4487.06                67      66.971045\n",
      "\n",
      "[89 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sales for each day\n",
    "daily_sales_query = \"\"\"\n",
    "SELECT \n",
    "    date AS sales_date, \n",
    "    SUM(total) AS total_sales_amount, \n",
    "    SUM(quantity) AS total_sales_units, \n",
    "    SUM(total) / SUM(quantity) AS avg_item_price\n",
    "FROM sales\n",
    "GROUP BY date\n",
    "ORDER BY date;\n",
    "\"\"\"\n",
    "cursor.execute(daily_sales_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Sales\n",
    "This query provides a summary of monthly sales, including the total sales amount, total sales units, and the average item price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sales_month total_sales_amount total_sales_units avg_item_price\n",
      "0     2019-01          116292.11              1965      59.181735\n",
      "1     2019-02           97219.58              1654      58.778464\n",
      "2     2019-03          109455.74              1891      57.882464\n"
     ]
    }
   ],
   "source": [
    "# Sales for each month\n",
    "monthly_sales_query = \"\"\"\n",
    "SELECT \n",
    "    DATE_FORMAT(date, '%Y-%m') AS sales_month, \n",
    "    SUM(total) AS total_sales_amount,\n",
    "    SUM(quantity) AS total_sales_units,\n",
    "    SUM(total) / SUM(quantity) AS avg_item_price\n",
    "FROM sales\n",
    "GROUP BY DATE_FORMAT(date, '%Y-%m')\n",
    "ORDER BY DATE_FORMAT(date, '%Y-%m');\n",
    "\"\"\"\n",
    "cursor.execute(monthly_sales_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly Sales\n",
    "This query provides a summary of weekly sales, including the total sales amount, total sales units, and the average item price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sales_week total_sales_amount total_sales_units avg_item_price\n",
      "0       201901           17543.40               305      57.519344\n",
      "1       201902           24461.26               431      56.754664\n",
      "2       201903           28693.43               461      62.241714\n",
      "3       201904           29286.95               489      59.891513\n",
      "4       201905           28360.53               484      58.596136\n",
      "5       201906           27101.89               506      53.561047\n",
      "6       201907           25563.65               399      64.069298\n",
      "7       201908           17328.70               314      55.186943\n",
      "8       201909           29219.75               465      62.838172\n",
      "9       201910           28418.94               496      57.296250\n",
      "10      201911           23990.24               447      53.669441\n",
      "11      201912           25120.66               405      62.026321\n",
      "12      201913           17878.03               308      58.045552\n"
     ]
    }
   ],
   "source": [
    "# Sales for each week\n",
    "weekly_sales_query = \"\"\"\n",
    "SELECT \n",
    "    YEARWEEK(date, 1) AS sales_week, \n",
    "    SUM(total) AS total_sales_amount,\n",
    "    SUM(quantity) AS total_sales_units,\n",
    "    SUM(total) / SUM(quantity) AS avg_item_price\n",
    "FROM sales\n",
    "GROUP BY YEARWEEK(date, 1)\n",
    "ORDER BY YEARWEEK(date, 1);\n",
    "\"\"\"\n",
    "cursor.execute(weekly_sales_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Preferences by Payment Method\n",
    "This query analyzes customer preferences by the payment method, showing the number of transactions and total sales amount for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       payment  number_of_transactions total_sales_amount\n",
      "0      Ewallet                     345          109993.38\n",
      "1         Cash                     344          112206.76\n",
      "2  Credit card                     311          100767.29\n"
     ]
    }
   ],
   "source": [
    "# Customer Preferences by Payment Method\n",
    "payment_method_query = \"\"\"\n",
    "SELECT payment, COUNT(*) AS number_of_transactions, SUM(total) AS total_sales_amount\n",
    "FROM sales\n",
    "GROUP BY payment\n",
    "ORDER BY number_of_transactions DESC;\n",
    "\"\"\"\n",
    "cursor.execute(payment_method_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Revenue per Customer Type\n",
    "This query calculates the average revenue per customer type (members vs. normal customers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_type total_revenue  total_customers avg_revenue_per_customer\n",
      "0        Member     164223.81              501               327.792036\n",
      "1        Normal     158743.62              499               318.123487\n"
     ]
    }
   ],
   "source": [
    "# The Average Revenue per Customer Type (Members vs. Normal)\n",
    "revenue_per_customer_type_query = \"\"\"\n",
    "WITH CustomerRevenue AS (\n",
    "    SELECT customer_type, SUM(total) AS total_revenue\n",
    "    FROM sales\n",
    "    GROUP BY customer_type\n",
    "),\n",
    "CustomerCount AS (\n",
    "    SELECT customer_type, COUNT(DISTINCT invoice_id) AS total_customers\n",
    "    FROM sales\n",
    "    GROUP BY customer_type\n",
    ")\n",
    "SELECT \n",
    "    cr.customer_type, cr.total_revenue, cc.total_customers,\n",
    "    cr.total_revenue / cc.total_customers AS avg_revenue_per_customer\n",
    "FROM CustomerRevenue cr\n",
    "JOIN CustomerCount cc ON cr.customer_type = cc.customer_type;\n",
    "\"\"\"\n",
    "cursor.execute(revenue_per_customer_type_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Patterns by Day and Time\n",
    "This query analyzes sales patterns across different days of the week and times of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    weekday  hour total_sales_amount\n",
      "0         1    10            4067.35\n",
      "1         1    11            4736.78\n",
      "2         1    12            4728.22\n",
      "3         1    13            5159.58\n",
      "4         1    14            4676.13\n",
      "..      ...   ...                ...\n",
      "72        7    16            3813.51\n",
      "73        7    17            5069.82\n",
      "74        7    18            6738.75\n",
      "75        7    19            9117.40\n",
      "76        7    20            3185.06\n",
      "\n",
      "[77 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sales Patterns across different days of the week and times of the day\n",
    "sales_patterns_query = \"\"\"\n",
    "WITH SalesWithWeekDay AS (\n",
    "    SELECT *, DAYOFWEEK(date) AS weekday\n",
    "    FROM sales\n",
    ")\n",
    "SELECT weekday, HOUR(time) AS hour, SUM(total) AS total_sales_amount\n",
    "FROM SalesWithWeekDay\n",
    "GROUP BY weekday, hour\n",
    "ORDER BY weekday, hour;\n",
    "\"\"\"\n",
    "cursor.execute(sales_patterns_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Segmentation by Spending\n",
    "This query segments customers based on their spending into high spenders, medium spenders, and low spenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch customer_type  gender total_spending spending_segment\n",
      "0       C        Member  Female       34653.51     High Spender\n",
      "1       C        Normal  Female       27032.05   Medium Spender\n",
      "2       A        Member    Male       26994.49   Medium Spender\n",
      "3       B        Member    Male       26854.30   Medium Spender\n",
      "4       B        Member  Female       26850.53   Medium Spender\n",
      "5       C        Normal    Male       26655.40   Medium Spender\n",
      "6       A        Member  Female       26643.08   Medium Spender\n",
      "7       A        Normal  Female       26626.16   Medium Spender\n",
      "8       B        Normal    Male       26415.24   Medium Spender\n",
      "9       B        Normal  Female       26077.93   Medium Spender\n",
      "10      A        Normal    Male       25936.84   Medium Spender\n",
      "11      C        Member    Male       22227.90      Low Spender\n"
     ]
    }
   ],
   "source": [
    "# Customer Segmentation Analysis based on their spending\n",
    "customer_segmentation_query = \"\"\"\n",
    "WITH CustomerSpending AS (\n",
    "    SELECT branch, customer_type, gender, SUM(total) AS total_spending\n",
    "    FROM sales\n",
    "    GROUP BY branch, customer_type, gender\n",
    ")\n",
    "SELECT branch, customer_type, gender, total_spending,\n",
    "    CASE\n",
    "        WHEN total_spending > 30000 THEN 'High Spender'\n",
    "        WHEN total_spending BETWEEN 25000 AND 30000 THEN 'Medium Spender'\n",
    "        ELSE 'Low Spender'\n",
    "    END AS spending_segment\n",
    "FROM CustomerSpending\n",
    "ORDER BY total_spending DESC;\n",
    "\"\"\"\n",
    "cursor.execute(customer_segmentation_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Forecasting\n",
    "This query forecasts future sales using a moving average window function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date daily_total_sales windowed_avg_week\n",
      "0   2019-01-01           4745.19       4745.190000\n",
      "1   2019-01-02           1945.50       3345.345000\n",
      "2   2019-01-03           2078.12       2922.936667\n",
      "3   2019-01-04           1623.68       2598.122500\n",
      "4   2019-01-05           3536.69       2785.836000\n",
      "..         ...               ...               ...\n",
      "84  2019-03-26           1962.52       3188.984286\n",
      "85  2019-03-27           2902.81       2823.927143\n",
      "86  2019-03-28           2229.42       2874.198571\n",
      "87  2019-03-29           4023.25       2994.784286\n",
      "88  2019-03-30           4487.06       3050.787143\n",
      "\n",
      "[89 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Forecasting Future Sales using a window function AVG()\n",
    "forecasting_sales_query = \"\"\"\n",
    "WITH DailySales AS (\n",
    "    SELECT date, SUM(total) AS daily_total_sales\n",
    "    FROM sales\n",
    "    GROUP BY date\n",
    "),\n",
    "MovingAverage AS (\n",
    "    SELECT date, daily_total_sales,\n",
    "        AVG(daily_total_sales) OVER (ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS windowed_avg_week\n",
    "    FROM DailySales\n",
    ")\n",
    "SELECT date, daily_total_sales, windowed_avg_week\n",
    "FROM MovingAverage\n",
    "ORDER BY date;\n",
    "\"\"\"\n",
    "cursor.execute(forecasting_sales_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Anomalies\n",
    "This query identifies days with unusually high or low sales based on statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date daily_total_sales    avg_sales  stddev_sales anomaly_type\n",
      "0  2019-02-07           7228.22  3628.847528   1519.034524         High\n",
      "1  2019-02-15           6830.79  3628.847528   1519.034524         High\n",
      "2  2019-03-09           7474.05  3628.847528   1519.034524         High\n",
      "3  2019-03-14           7214.63  3628.847528   1519.034524         High\n"
     ]
    }
   ],
   "source": [
    "# Anomaly in Sales (Identifying days with unusually high or low sales)\n",
    "sales_anomaly_query = \"\"\"\n",
    "WITH DailySales AS (\n",
    "    SELECT date, SUM(total) AS daily_total_sales\n",
    "    FROM sales\n",
    "    GROUP BY date\n",
    "),\n",
    "SalesStats AS (\n",
    "    SELECT AVG(daily_total_sales) AS avg_sales, STDDEV(daily_total_sales) AS stddev_sales\n",
    "    FROM DailySales\n",
    ")\n",
    "SELECT \n",
    "    ds.date, ds.daily_total_sales, ss.avg_sales, ss.stddev_sales,\n",
    "    CASE\n",
    "        WHEN ds.daily_total_sales > ss.avg_sales + 2 * ss.stddev_sales THEN 'High'\n",
    "        WHEN ds.daily_total_sales < ss.avg_sales - 2 * ss.stddev_sales THEN 'Low'\n",
    "        ELSE 'None'\n",
    "    END AS anomaly_type\n",
    "FROM DailySales ds\n",
    "CROSS JOIN SalesStats ss \n",
    "WHERE ds.daily_total_sales > ss.avg_sales + 2 * ss.stddev_sales \n",
    "   OR ds.daily_total_sales < ss.avg_sales - 2 * ss.stddev_sales\n",
    "ORDER BY ds.date;\n",
    "\"\"\"\n",
    "cursor.execute(sales_anomaly_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# To display the results in a DataFrame, so that it is easier to read\n",
    "df_result = query_to_dataframe(cursor, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End of the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the cursor and connection\n",
    "if cursor:\n",
    "    cursor.close()\n",
    "if connection:\n",
    "    connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
